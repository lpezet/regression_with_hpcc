# 1.0 Introduction

This walkthrough on regression and modeling follows the SAS version that inspired it, written by the brilliant people from UCLA Idrea. It can be found here: [REGRESSION WITH SAS CHAPTER 1 – SIMPLE AND MULTIPLE REGRESSION](https://stats.idre.ucla.edu/sas/webbooks/reg/chapter1/regressionwith-saschapter-1-simple-and-multiple-regression/)
This article will try to follow each step taken in the original web book, try to replicate it in HPCC ECL, and present results and hopefully explain differences and where to go from there.

The emphasize will be on understanding data by running some simple analysis to find more actionable and useful means to come up with predictive models.

I assume that you already have a basic understanding of HPCC ECL, and that you have basic environment running (e.g. VirtualBox VM is fine for this exercise).

The data used here was created by randomly sampling 400 elementary schools from the California Department of Education’s API 2000 dataset. This data file contains a measure of school academic performance as well as other attributes of the elementary schools, such as, class size, enrollment, poverty, etc.
There are two versions of the data as we will see shortly, one which is *raw* (i.e. dirty) and one that has been cleaned up and used later.

The SAS *raw* file is [elemapi.sas7bdat](https://stats.idre.ucla.edu/wp-content/uploads/2016/02/elemapi-1.sas7bdat). This is the file we will be using from now on until mentioned otherwise.

## 1.0.1 Setting things up

Best is to simply clone this repository and add the containing folder to your **ECL Folders** in your ECL IDE.


## 1.0.2 Loading data

Best is to simply to use ECL Watch to upload the data file to the dropzone and spray it as CSV.
To make things faster, this ECL code will basically do the same.
Open the file `Chap1_0_GettingStarted.ecl` and submit it.


This code simply extracts the data by downloading the data files contained in this project and extracting their content.
The CSV files we're interested in here are then available in the dropzone.
Data is then loaded as "raw" data, where all fields are basically of the *STRING* type. It's best to start this way to examine the data and make sure nothing is **lost in translation** when using final field types.


# 1.1 Examining data

Before getting to the nitty gritty, it's best to understand what kind of data we are dealing with.
As far as I know, there's today no HPCC data file format that would store both the data and its description.
The following **RECORD** will have to suffice for now:

```ecl
raw_layout := RECORD
 STRING snum;       // school number
 STRING dnum;       // district number
 STRING api00;      // academic school Performan in 2000
 STRING api99;      // academic school performance in 1999
 STRING growth;     // growth 1999 to 2000
 STRING meals;      // percent free meals
 STRING ell;        // english language learners
 STRING yr_rnd;     // year round school
 STRING mobility;   // percent 1st year in school
 STRING acs_k3;     // average class size k-3
 STRING acs_46;     // average class size 4-6
 STRING not_hsg;    // parent not hsg
 STRING hsg;        // parent hsg
 STRING some_col;   // parent some college
 STRING col_grad;   // parent college grad
 STRING grad_sch;   // parent grad school
 STRING avg_ed;     // average parent ed
 STRING full;       // percent full credential
 STRING emer;       // percent emer credential
 STRING enroll;     // number of students
 STRING mealcat;    // percent free means in 3 categories
 STRING collcat;    // 
END;
```

The data file contains academic performance, average class sizes, percent of student eligible for free meals, parents education, percent of teachers with full and emergency credentials, number of enrollees, etc. per school.

Load and submit the `Chap1_1_ExaminingData.ecl` file.
Let's look at the outputs.

## 1.1.1 Sample of raw data

The output `SampleRaw` shows 100 records loaded from the `elemapi-1.csv` file, as is.
This is generated by the following action:

```
OUTPUT( oDS, NAMED('SampleRaw') );
```

Here are the first 10 records from this output:

| snum | dnum | api00 | api99 | growth | meals | ell | yr_rnd | mobility | acs_k3 | acs_46 | not_hsg | hsg | some_col | col_grad | grad_sch | avg_ed | full | emer | enroll | mealcat | collcat |
| ---- | ----- | ----- | ---- | ---- | --- | --- | ---- | ---- | ---- | --- | --- | --- | --- | --- | --- | ---- | ---- | ----- | --- | --- | --- |
| 906 | 41 | 693 | 600 | 93 | 67 | 9 | 0 | 11 | 16 | 22 | 0 | 0 | 0 | 0 | 0 |  | 76 | 24 | 247 | 2 | |
| 889 | 41 | 570 | 501 | 69 | 92 | 21 | 0 | 33 | 15 | 32 | 0 | 0 | 0 | 0 | 0 |  | 79 | 19 | 463 | 3 | | 
| 887 | 41 | 546 | 472 | 74 | 97 | 29 | 0 | 36 | 17 | 25 | 0 | 0 | 0 | 0 | 0 |  | 68 | 29 | 395 | 3 | |
| 876 | 41 | 571 | 487 | 84 | 90 | 27 | 0 | 27 | 20 | 30 | 36 | 45 | 9 | 9 | 0 | 1.909999966621399 | 87 | 11 | 418 | 3 | |
| 888 | 41 | 478 | 425 | 53 | 89 | 30 | 0 | 44 | 18 | 31 | 50 | 50 | 0 | 0 | 0 | 1.5 | 87 | 13 | 520 | 3 | |
| 4284 | 98 | 858 | 844 | 14 |  | 3 | 0 | 10 | 20 | 33 | 1 | 8 | 24 | 36 | 31 | 3.890000104904175 | 100 | 0 | 343 | 1 | |
| 4271 | 98 | 918 | 864 | 54 |  | 2 | 0 | 16 | 19 | 28 | 1 | 4 | 18 | 34 | 43 | 4.130000114440918 | 100 | 0 | 303 | 1 | |
| 2910 | 108 | 831 | 791 | 40 |  | 3 | 0 | 44 | 20 | 31 | 0 | 4 | 16 | 50 | 30 | 4.059999942779541 | 96 | 2 | 1513 | 1 | |
| 2899 | 108 | 860 | 838 | 22 |  | 6 | 0 | 10 | 20 | 30 | 2 | 9 | 15 | 42 | 33 | 3.9600000381469727 | 100 | 0 | 660 | 1 | |
| 2887 | 108 | 737 | 703 | 34 | 29 | 15 | 0 | 17 | 21 | 29 | 8 | 25 | 34 | 27 | 7 | 2.9800000190734863 | 96 | 7 | 362 | 1 | |
| ... | ..... | ..... | .... | .... | ... | ... | .... | .... | .... | ... | ... | ... | ... | ... | ... | .... | .... | ..... | ... | ... | ... | 

Listing data can be helpful to eyeball problems within it. In this sample, we can clearly see that some values are missing for *meals*., as well as fr *avg_ed*.
Thing is, it's possible we might be missing values for other fields that we can't see here because we're looking at only 100 records.

A useful way to learn about the data at hand is to get basic statistics on the fields we're interested in, like minimum value, maximum value, average, etc.
I provided a module called `Profiler` that will help with this task and shows in the next outputs.
 
## 1.1.2 All Fields
 
The `AllFields` output shows information for all fields.
This is generated from the action below:

```
Profiler.profile_fields( oProfileAllFields, oDS );
OUTPUT( oProfileAllFields, NAMED('AllFields') );
```

Which outputs the following:

| field | obs | min_value | max_value | min_value_length | max_value_length |
| -- | -- | -- | -- | -- | -- | 
| acs_46 | 397 | 20 | 50 | 2 | 2 |
| acs_k3 | 398 | -19 | 25 | 2 | 3 |
| api00 | 400 | 369 | 940 | 3 | 3 |
| api99 | 400 | 333 | 917 | 3 | 3 |
| avg_ed | 381 | 1 | 4.619999885559082 | 1 | 18 |
| ... | ... | ... | ... | ... | ... | 


It is now very easy to see now if (where) we are missing values for any of those fields.
Any field with less than 400 observations is a field with at least one missing value (empty).



## 1.1.3 Select Fields Values

The next output is `SelectFieldsValues` which shows some information on the values of each select fields.

The ECL code to generate such output is as follows:

```
Profiler.profile_select_fields_values( oProfileSelectFieldsValues, oDS, 'full,meals,acs_k3,api00' );
OUTPUT( oProfileSelectFieldsValues, NAMED('SelectFieldsValues') );
```

Which generates the following:

| field | value | freq |
| --- | --- | --- |
| acs_k3 | | 2 |
| acs_k3 | -19 | 1 |
| acs_k3 | -20 | 2 |
| acs_k3 | -21 | 3 |
| acs_k3 | 14 | 2 |
| ... | ... | ... |


Where the previous outputs helped understand where values were missing, this one provide a little more information on actual values by field and their frequency.
For instance, we knew already that `acs_k3` had values missing (since its ``obs = 398`` ) but here we also see some of those negative values as well.


## 1.1.4 Meals Frequency

MealsFrequency

This can be easily done using the free Machine Learning library provided by HPCC Systems.
 
 
The output is as follows:
 
| field_name | number | minval | maxval | sumval | countval | mean | var | sd |
| ----- | -- | ---- | ---- | ------- | ----- | ----------------- | --------------- | ---------------- |
| acs_k3 | 10 | 0.0 | 50.0 | 11399.0 | 386.0 | 29.53108808290155 | 21.518463582915 | 4.63879979983131 |
| full | 18 | 0.0 | 59.0 | 4984.0 | 386.0 | 12.9119170984456 | 142.1269564283605 | 11.92170107108715 |
| api00 | 3 | 333.0 | 917.0 | 236741.0 | 386.0 | 613.3186528497409 | 21605.42954844422 | 146.9878551052576 |
| meals | 6 | 0.0 | 91.0 | 12307.0 | 386.0 | 31.88341968911917 | 632.1962535907005 | 25.14351315132196 |

WARNING: Again here, because of SAS Viewer export, some observations made from UCLA is off here, since we don't see like -21 for min val of acs_k3.


TODO: freq for yr_rnd
TODO: univariate acs_k3
TODO: tables acs_k3
TODO: troubleshoot negatie values for acs_k3
TODO: troubleshoot full <= 1
TODO: scatter plots!!!
TODO; regression!!!!



